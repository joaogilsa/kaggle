{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve,classification_report,auc,precision_score,recall_score,precision_recall_curve,median_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"data\", \"train.csv\")) as f:\n",
    "    # read the training dataset\n",
    "    df = pd.read_csv(f, index_col = 'id')\n",
    "\n",
    "with open(os.path.join(\"data\", \"test.csv\")) as f:\n",
    "    # read the test dataset\n",
    "    X_test = pd.read_csv(f, index_col = 'id')\n",
    "\n",
    "\n",
    "X = df.drop(['Hardness'], axis=1)\n",
    "y = df['Hardness']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;processing&#x27;, MinMaxScaler()),\n",
       "                (&#x27;regressor&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;processing&#x27;, MinMaxScaler()),\n",
       "                (&#x27;regressor&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('processing', MinMaxScaler()),\n",
       "                ('regressor', LinearRegression())])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join('pickles/baseline', 'columns.json')) as fh:\n",
    "    columns = json.load(fh)\n",
    "\n",
    "with open(os.path.join('pickles/baseline', 'dtypes.pickle'), 'rb') as fh:\n",
    "    dtypes = pickle.load(fh)\n",
    "\n",
    "with open(os.path.join('pickles/baseline', 'pipeline.pickle'), 'rb') as fh:\n",
    "    pipeline_base = joblib.load(fh)\n",
    "\n",
    "features = X.columns\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "X_train_baseline = X_train[features]\n",
    "\n",
    "pipeline_base.fit(X_train_baseline, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_base\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedian Absolute Error score of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m'\u001b[39m,log_loss(y_val, y_val_pred)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline_base' is not defined"
     ]
    }
   ],
   "source": [
    "y_val_pred = pipeline_base.predict(X_val)\n",
    "\n",
    "print('Median Absolute Error score of {}: {}'.format('baseline',median_absolute_error(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Median Absolute Error with LightGBM | MedAE: 0.6452822745961022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Baseline': 0.9555663913173742,\n",
       " 'LightGBM': 0.6452822745961022,\n",
       " 'Random Forest': 0.645478039694277,\n",
       " 'Decision Tree': 0.7000000000000002,\n",
       " 'SVR': 0.6527384090608557}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = preprocessing.MinMaxScaler()\n",
    "\n",
    "pipeline_light = Pipeline(steps=[('processing',process),\n",
    "                     ('regressor', lgb.LGBMRegressor(learning_rate=0.09,max_depth=-15,random_state=42))])\n",
    "\n",
    "pipeline_rf = Pipeline(steps = [('processing', process),\n",
    "                                ('regressor',RandomForestRegressor(max_depth=15,random_state = 42))])\n",
    "\n",
    "pipeline_dt = Pipeline(steps=[('processing', process),\n",
    "                              ('regressor', DecisionTreeRegressor(max_depth=15,random_state = 42))])\n",
    "\n",
    "pipeline_svr = Pipeline(steps=[('processing', process),\n",
    "                              ('regressor', SVR())])\n",
    "\n",
    "\n",
    "pipelines = [pipeline_base, pipeline_light, pipeline_rf, pipeline_dt, pipeline_svr]\n",
    "pipe_dict = {0: 'Baseline', 1: 'LightGBM', 2:'Random Forest', 3: 'Decision Tree', 4: 'SVR'}\n",
    "\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "best_precision = 0.0\n",
    "best_regressor = 0\n",
    "best_medae = 10\n",
    "best_pipeline = ''\n",
    "prediction_dict={}\n",
    "\n",
    "for i, model in enumerate(pipelines) : \n",
    "    y_val_pred = model.predict(X_val)\n",
    "    medae = median_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    prediction_dict[pipe_dict[i]] = medae\n",
    "\n",
    "    if medae < best_medae:\n",
    "        best_medae = medae\n",
    "        best_pipeline = model\n",
    "        best_regressor = i\n",
    "print('Best Median Absolute Error with {} | MedAE: {}'.format(pipe_dict[best_regressor],best_medae))\n",
    "\n",
    "prediction_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.635 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.618 total time=   0.2s\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.588 total time=   0.2s\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.661 total time=   0.2s\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.582 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.595 total time=   0.3s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.635 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.628 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.563 total time=   0.3s\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.618 total time=   0.1s\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.523 total time=   0.2s\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.558 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.661 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.582 total time=   0.1s\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.588 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.601 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.572 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.619 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.958 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.555 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.521 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.872 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.858 total time=   0.1s\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.942 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-1.000 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.947 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.857 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.921 total time=   0.2s\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.841 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.963 total time=   0.2s\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.958 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.872 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.942 total time=   0.1s\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.858 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-1.000 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.947 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.857 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.921 total time=   0.2s\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.841 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.617 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.682 total time=   0.1s\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.611 total time=   0.1s\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.963 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.605 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.564 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.576 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.563 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.615 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.536 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.617 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.530 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.611 total time=   0.1s\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.682 total time=   0.1s\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.605 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.564 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.576 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.563 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.975 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.615 total time=   0.2s\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.525 total time=   0.2s\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.536 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.868 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.929 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.871 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.997 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.958 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.866 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.975 total time=   0.1s\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.921 total time=   0.3s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.841 total time=   0.3s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.958 total time=   0.3s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.868 total time=   0.2s\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.929 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.871 total time=   0.2s\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.997 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.958 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.866 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.921 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.841 total time=   0.2s\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.635 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5] END bagging_fraction=0.6, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.958 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.618 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.661 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.588 total time=   0.1s\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.582 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.595 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.563 total time=   0.2s\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.628 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.635 total time=   0.2s\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.558 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.523 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.618 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.588 total time=   0.1s\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.661 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.582 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.601 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.572 total time=   0.2s\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.619 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.958 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.555 total time=   0.2s\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.521 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.872 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.942 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.858 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-1.000 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.947 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.857 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.921 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.958 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.841 total time=   0.2s\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.963 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.872 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.942 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.858 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-1.000 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.947 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.857 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.921 total time=   0.2s\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.841 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.6, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.963 total time=   0.2s\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.617 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.611 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.682 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.605 total time=   0.1s\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=7, objective=mae;, score=-0.564 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.576 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.563 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.615 total time=   0.2s\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.617 total time=   0.2s\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.536 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=10, num_leaves=15, objective=mae;, score=-0.530 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.611 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.682 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.605 total time=   0.2s\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=7, objective=mae;, score=-0.564 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.576 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.563 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.615 total time=   0.2s\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.536 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.975 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.05, max_depth=15, num_leaves=15, objective=mae;, score=-0.525 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.868 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.929 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.871 total time=   0.1s\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=7, objective=mae;, score=-0.997 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.958 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.866 total time=   0.2s\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.975 total time=   0.2s\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.921 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.841 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=10, num_leaves=15, objective=mae;, score=-0.958 total time=   0.3s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.868 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.871 total time=   0.1s\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.929 total time=   0.2s\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=7, objective=mae;, score=-0.997 total time=   0.1s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV 1/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.958 total time=   0.2s\n",
      "[CV 2/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.866 total time=   0.2s\n",
      "[CV 3/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.921 total time=   0.2s\n",
      "[CV 5/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.958 total time=   0.2s\n",
      "[CV 4/5] END bagging_fraction=0.8, boosting=gbdt, feature_fraction=0.8, learning_rate=0.005, max_depth=15, num_leaves=15, objective=mae;, score=-0.841 total time=   0.2s\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "best params\n",
      "{'bagging_fraction': 0.6, 'boosting': 'gbdt', 'feature_fraction': 0.8, 'learning_rate': 0.05, 'max_depth': 15, 'num_leaves': 15, 'objective': 'mae'}\n"
     ]
    }
   ],
   "source": [
    "# light_grid = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "\n",
    "# parameters = {\n",
    "#     # 'task' : ['predict'],\n",
    "#     'boosting': ['gbdt' ],\n",
    "#     'objective': ['mae'],\n",
    "#     #'num_iterations': [  1500, 2000  ],\n",
    "#     'learning_rate':[  0.05, 0.005 ],\n",
    "#     'num_leaves':[ 7, 15 ],\n",
    "#     'max_depth' :[ 10,15],\n",
    "#     #'min_data_in_leaf':[15,25],\n",
    "#     'feature_fraction': [ 0.6, 0.8],\n",
    "#     'bagging_fraction': [  0.6, 0.8 ],\n",
    "#     #'bagging_freq': [   100, 200, 400  ], \n",
    "# }\n",
    "\n",
    "# grid_lgb = GridSearchCV(light_grid, param_grid = parameters, n_jobs=6, verbose=3, scoring = 'neg_median_absolute_error', cv = 5)\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# grid_lgb.fit(X_train_scaled,y_train)\n",
    " \n",
    "\n",
    "# print('best params')\n",
    "# print(grid_lgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5382103325544856\n"
     ]
    }
   ],
   "source": [
    "# X_val_scaled = scaler.transform(X_val)\n",
    "# y_val_pred_grid = grid_lgb.predict(X_val_scaled)\n",
    "# medae_grid = median_absolute_error(y_val, y_val_pred_grid)\n",
    "# print(medae_grid)\n",
    "# print(grid_lgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n"
     ]
    }
   ],
   "source": [
    "# Pipeline using the grid-optimized lightGBM model\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "pipeline_grid_light = Pipeline([('scaler', scaler),\n",
    "                          ('regressor', lgb.LGBMRegressor(random_state=42, bagging_fraction = 0.6,\n",
    "                                                          boosting = 'gbdt', feature_fraction = 0.6,\n",
    "                                                          learning_rate = 0.05, max_depth = 15,\n",
    "                                                          num_leaves = 15, objective= 'mae'))])\n",
    "\n",
    "pipeline_grid_light.fit(X, y)\n",
    "\n",
    "y_test_pred = pipeline_grid_light.predict(X_test)\n",
    "\n",
    "# output = pd.DataFrame({'id': X_test.index,\n",
    "#                        'emission': y_test_pred})\n",
    "\n",
    "# from datetime import date, datetime\n",
    "# now = datetime.now()\n",
    "# today_str = now.strftime(\"%d%m%Y_%H%M\")\n",
    "\n",
    "# subm_file_name = \"submissions/submission_\"+today_str+\".csv\"\n",
    "\n",
    "# output.to_csv(subm_file_name, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "---\n",
      "Validation error:\n",
      "Mean: -0.56% | Variance: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.51842542, -0.53373033, -0.60288837, -0.5647964 , -0.59549626])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(pipeline_grid_light, X, y, cv=5, scoring='neg_median_absolute_error')\n",
    "mean_error = round(np.mean(scores), 2)\n",
    "var_error = round(np.var(scores), 2)\n",
    "print(f'---\\nValidation error:\\nMean: {mean_error}% | Variance: {var_error}')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on Kaggle: 0.5141"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END degree=3, gamma=scale, kernel=linear;, score=-0.795 total time=   3.4s\n",
      "[CV 3/5] END degree=3, gamma=scale, kernel=linear;, score=-0.822 total time=   3.4s\n",
      "[CV 5/5] END degree=3, gamma=scale, kernel=linear;, score=-0.833 total time=   3.4s\n",
      "[CV 1/5] END degree=3, gamma=scale, kernel=linear;, score=-0.826 total time=   3.4s\n",
      "[CV 2/5] END degree=3, gamma=scale, kernel=linear;, score=-0.837 total time=   3.5s\n",
      "[CV 1/5] END degree=3, gamma=scale, kernel=poly;, score=-0.733 total time=   4.6s\n",
      "[CV 4/5] END degree=3, gamma=scale, kernel=poly;, score=-0.702 total time=   3.5s\n",
      "[CV 5/5] END degree=3, gamma=scale, kernel=poly;, score=-0.737 total time=   3.6s\n",
      "[CV 2/5] END degree=3, gamma=scale, kernel=poly;, score=-0.785 total time=   3.7s\n",
      "[CV 3/5] END degree=3, gamma=scale, kernel=poly;, score=-0.782 total time=   3.9s\n",
      "[CV 1/5] END degree=3, gamma=scale, kernel=rbf;, score=-0.699 total time=   4.5s\n",
      "[CV 2/5] END degree=3, gamma=scale, kernel=rbf;, score=-0.722 total time=   4.5s\n",
      "[CV 3/5] END degree=3, gamma=scale, kernel=rbf;, score=-0.775 total time=   4.6s\n",
      "[CV 4/5] END degree=3, gamma=scale, kernel=rbf;, score=-0.683 total time=   4.6s\n",
      "[CV 5/5] END degree=3, gamma=scale, kernel=rbf;, score=-0.684 total time=   4.6s\n",
      "[CV 1/5] END degree=3, gamma=scale, kernel=sigmoid;, score=-1.218 total time=   5.0s\n",
      "[CV 2/5] END degree=3, gamma=scale, kernel=sigmoid;, score=-1.145 total time=   5.2s\n",
      "[CV 3/5] END degree=3, gamma=scale, kernel=sigmoid;, score=-1.129 total time=   5.2s\n",
      "[CV 1/5] END degree=3, gamma=auto, kernel=linear;, score=-0.826 total time=   2.8s\n",
      "[CV 2/5] END degree=3, gamma=auto, kernel=linear;, score=-0.837 total time=   2.8s\n",
      "[CV 3/5] END degree=3, gamma=auto, kernel=linear;, score=-0.822 total time=   2.9s\n",
      "[CV 4/5] END degree=3, gamma=scale, kernel=sigmoid;, score=-1.076 total time=   5.4s\n",
      "[CV 5/5] END degree=3, gamma=scale, kernel=sigmoid;, score=-1.212 total time=   5.4s\n",
      "[CV 4/5] END degree=3, gamma=auto, kernel=linear;, score=-0.795 total time=   2.9s\n",
      "[CV 5/5] END degree=3, gamma=auto, kernel=linear;, score=-0.833 total time=   2.9s\n",
      "[CV 1/5] END degree=3, gamma=auto, kernel=poly;, score=-0.914 total time=   3.3s\n",
      "[CV 2/5] END degree=3, gamma=auto, kernel=poly;, score=-0.900 total time=   3.3s\n",
      "[CV 3/5] END degree=3, gamma=auto, kernel=poly;, score=-0.891 total time=   3.3s\n",
      "[CV 4/5] END degree=3, gamma=auto, kernel=poly;, score=-0.837 total time=   3.3s\n",
      "[CV 5/5] END degree=3, gamma=auto, kernel=poly;, score=-0.915 total time=   3.3s\n",
      "[CV 1/5] END .degree=3, gamma=auto, kernel=rbf;, score=-0.841 total time=   4.9s\n",
      "[CV 2/5] END .degree=3, gamma=auto, kernel=rbf;, score=-0.831 total time=   4.8s\n",
      "[CV 1/5] END degree=3, gamma=auto, kernel=sigmoid;, score=-0.869 total time=   3.3s\n",
      "[CV 3/5] END .degree=3, gamma=auto, kernel=rbf;, score=-0.843 total time=   4.5s\n",
      "[CV 4/5] END .degree=3, gamma=auto, kernel=rbf;, score=-0.791 total time=   4.4s\n",
      "[CV 5/5] END .degree=3, gamma=auto, kernel=rbf;, score=-0.841 total time=   4.4s\n",
      "[CV 2/5] END degree=3, gamma=auto, kernel=sigmoid;, score=-0.857 total time=   3.6s\n",
      "[CV 3/5] END degree=3, gamma=auto, kernel=sigmoid;, score=-0.856 total time=   3.6s\n",
      "[CV 4/5] END degree=3, gamma=auto, kernel=sigmoid;, score=-0.818 total time=   3.7s\n",
      "[CV 1/5] END degree=6, gamma=scale, kernel=linear;, score=-0.826 total time=   2.9s\n",
      "[CV 5/5] END degree=3, gamma=auto, kernel=sigmoid;, score=-0.883 total time=   3.7s\n",
      "[CV 2/5] END degree=6, gamma=scale, kernel=linear;, score=-0.837 total time=   3.0s\n",
      "[CV 3/5] END degree=6, gamma=scale, kernel=linear;, score=-0.822 total time=   2.9s\n",
      "[CV 4/5] END degree=6, gamma=scale, kernel=linear;, score=-0.795 total time=   2.8s\n",
      "[CV 5/5] END degree=6, gamma=scale, kernel=linear;, score=-0.833 total time=   2.8s\n",
      "[CV 1/5] END degree=6, gamma=scale, kernel=rbf;, score=-0.699 total time=   4.9s\n",
      "[CV 2/5] END degree=6, gamma=scale, kernel=rbf;, score=-0.722 total time=   4.6s\n",
      "[CV 3/5] END degree=6, gamma=scale, kernel=rbf;, score=-0.775 total time=   4.5s\n",
      "[CV 4/5] END degree=6, gamma=scale, kernel=rbf;, score=-0.683 total time=   3.9s\n",
      "[CV 5/5] END degree=6, gamma=scale, kernel=rbf;, score=-0.684 total time=   4.1s\n",
      "[CV 1/5] END degree=6, gamma=scale, kernel=sigmoid;, score=-1.218 total time=   4.8s\n",
      "[CV 2/5] END degree=6, gamma=scale, kernel=sigmoid;, score=-1.145 total time=   4.7s\n",
      "[CV 3/5] END degree=6, gamma=scale, kernel=sigmoid;, score=-1.129 total time=   4.4s\n",
      "[CV 4/5] END degree=6, gamma=scale, kernel=poly;, score=-0.651 total time=  40.7s\n",
      "[CV 2/5] END degree=6, gamma=scale, kernel=poly;, score=-0.707 total time=  43.0s\n",
      "[CV 4/5] END degree=6, gamma=scale, kernel=sigmoid;, score=-1.076 total time=   4.5s\n",
      "[CV 3/5] END degree=6, gamma=scale, kernel=poly;, score=-0.737 total time=  43.4s\n",
      "[CV 1/5] END degree=6, gamma=auto, kernel=linear;, score=-0.826 total time=   2.9s\n",
      "[CV 2/5] END degree=6, gamma=auto, kernel=linear;, score=-0.837 total time=   2.9s\n",
      "[CV 3/5] END degree=6, gamma=auto, kernel=linear;, score=-0.822 total time=   3.1s\n",
      "[CV 5/5] END degree=6, gamma=scale, kernel=sigmoid;, score=-1.212 total time=   5.3s\n",
      "[CV 1/5] END degree=6, gamma=scale, kernel=poly;, score=-0.669 total time=  48.2s\n",
      "[CV 5/5] END degree=6, gamma=scale, kernel=poly;, score=-0.652 total time=  46.5s\n",
      "[CV 4/5] END degree=6, gamma=auto, kernel=linear;, score=-0.795 total time=   3.4s\n",
      "[CV 5/5] END degree=6, gamma=auto, kernel=linear;, score=-0.833 total time=   3.5s\n",
      "[CV 1/5] END degree=6, gamma=auto, kernel=poly;, score=-1.103 total time=   4.4s\n",
      "[CV 2/5] END degree=6, gamma=auto, kernel=poly;, score=-1.073 total time=   4.2s\n",
      "[CV 3/5] END degree=6, gamma=auto, kernel=poly;, score=-1.088 total time=   4.2s\n",
      "[CV 4/5] END degree=6, gamma=auto, kernel=poly;, score=-1.061 total time=   4.1s\n",
      "[CV 5/5] END degree=6, gamma=auto, kernel=poly;, score=-1.143 total time=   3.8s\n",
      "[CV 1/5] END .degree=6, gamma=auto, kernel=rbf;, score=-0.841 total time=   5.2s\n",
      "[CV 2/5] END .degree=6, gamma=auto, kernel=rbf;, score=-0.831 total time=   4.5s\n",
      "[CV 3/5] END .degree=6, gamma=auto, kernel=rbf;, score=-0.843 total time=   4.5s\n",
      "[CV 1/5] END degree=6, gamma=auto, kernel=sigmoid;, score=-0.869 total time=   3.2s\n",
      "[CV 4/5] END .degree=6, gamma=auto, kernel=rbf;, score=-0.791 total time=   4.3s\n",
      "[CV 5/5] END .degree=6, gamma=auto, kernel=rbf;, score=-0.841 total time=   4.2s\n",
      "[CV 2/5] END degree=6, gamma=auto, kernel=sigmoid;, score=-0.857 total time=   3.4s\n",
      "[CV 3/5] END degree=6, gamma=auto, kernel=sigmoid;, score=-0.856 total time=   3.3s\n",
      "[CV 1/5] END degree=9, gamma=scale, kernel=linear;, score=-0.826 total time=   2.5s\n",
      "[CV 4/5] END degree=6, gamma=auto, kernel=sigmoid;, score=-0.818 total time=   3.3s\n",
      "[CV 2/5] END degree=9, gamma=scale, kernel=linear;, score=-0.837 total time=   2.4s\n",
      "[CV 5/5] END degree=6, gamma=auto, kernel=sigmoid;, score=-0.883 total time=   3.3s\n",
      "[CV 3/5] END degree=9, gamma=scale, kernel=linear;, score=-0.822 total time=   2.3s\n",
      "[CV 4/5] END degree=9, gamma=scale, kernel=linear;, score=-0.795 total time=   2.4s\n",
      "[CV 5/5] END degree=9, gamma=scale, kernel=linear;, score=-0.833 total time=   2.3s\n",
      "[CV 1/5] END degree=9, gamma=scale, kernel=rbf;, score=-0.699 total time=   4.0s\n",
      "[CV 2/5] END degree=9, gamma=scale, kernel=rbf;, score=-0.722 total time=   4.0s\n",
      "[CV 3/5] END degree=9, gamma=scale, kernel=rbf;, score=-0.775 total time=   4.0s\n",
      "[CV 4/5] END degree=9, gamma=scale, kernel=rbf;, score=-0.683 total time=   3.9s\n",
      "[CV 5/5] END degree=9, gamma=scale, kernel=rbf;, score=-0.684 total time=   3.9s\n",
      "[CV 1/5] END degree=9, gamma=scale, kernel=sigmoid;, score=-1.218 total time=   4.3s\n",
      "[CV 2/5] END degree=9, gamma=scale, kernel=sigmoid;, score=-1.145 total time=   4.3s\n",
      "[CV 3/5] END degree=9, gamma=scale, kernel=sigmoid;, score=-1.129 total time=   4.3s\n",
      "[CV 4/5] END degree=9, gamma=scale, kernel=sigmoid;, score=-1.076 total time=   4.3s\n",
      "[CV 5/5] END degree=9, gamma=scale, kernel=sigmoid;, score=-1.212 total time=   4.2s\n",
      "[CV 1/5] END degree=9, gamma=auto, kernel=linear;, score=-0.826 total time=   2.3s\n",
      "[CV 2/5] END degree=9, gamma=auto, kernel=linear;, score=-0.837 total time=   2.3s\n",
      "[CV 3/5] END degree=9, gamma=auto, kernel=linear;, score=-0.822 total time=   2.2s\n",
      "[CV 4/5] END degree=9, gamma=auto, kernel=linear;, score=-0.795 total time=   2.2s\n",
      "[CV 5/5] END degree=9, gamma=auto, kernel=linear;, score=-0.833 total time=   2.5s\n",
      "[CV 1/5] END degree=9, gamma=auto, kernel=poly;, score=-1.103 total time=   2.6s\n",
      "[CV 2/5] END degree=9, gamma=auto, kernel=poly;, score=-1.100 total time=   2.6s\n",
      "[CV 3/5] END degree=9, gamma=auto, kernel=poly;, score=-1.101 total time=   2.6s\n",
      "[CV 4/5] END degree=9, gamma=auto, kernel=poly;, score=-1.099 total time=   2.7s\n",
      "[CV 5/5] END degree=9, gamma=auto, kernel=poly;, score=-1.105 total time=   2.7s\n",
      "[CV 1/5] END .degree=9, gamma=auto, kernel=rbf;, score=-0.841 total time=   3.9s\n",
      "[CV 2/5] END .degree=9, gamma=auto, kernel=rbf;, score=-0.831 total time=   3.9s\n",
      "[CV 3/5] END .degree=9, gamma=auto, kernel=rbf;, score=-0.843 total time=   4.1s\n",
      "[CV 4/5] END .degree=9, gamma=auto, kernel=rbf;, score=-0.791 total time=   3.9s\n",
      "[CV 5/5] END .degree=9, gamma=auto, kernel=rbf;, score=-0.841 total time=   4.1s\n",
      "[CV 1/5] END degree=9, gamma=auto, kernel=sigmoid;, score=-0.869 total time=   3.0s\n",
      "[CV 2/5] END degree=9, gamma=auto, kernel=sigmoid;, score=-0.857 total time=   3.1s\n",
      "[CV 3/5] END degree=9, gamma=auto, kernel=sigmoid;, score=-0.856 total time=   3.1s\n",
      "[CV 4/5] END degree=9, gamma=auto, kernel=sigmoid;, score=-0.818 total time=   3.0s\n",
      "[CV 5/5] END degree=9, gamma=auto, kernel=sigmoid;, score=-0.883 total time=   3.0s\n",
      "[CV 4/5] END degree=9, gamma=scale, kernel=poly;, score=-0.693 total time=60.0min\n",
      "[CV 1/5] END degree=9, gamma=scale, kernel=poly;, score=-0.720 total time=62.5min\n",
      "[CV 3/5] END degree=9, gamma=scale, kernel=poly;, score=-0.737 total time=71.8min\n",
      "[CV 2/5] END degree=9, gamma=scale, kernel=poly;, score=-0.693 total time=71.8min\n",
      "[CV 5/5] END degree=9, gamma=scale, kernel=poly;, score=-0.672 total time=76.9min\n",
      "best params\n",
      "{'degree': 6, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "# SVR_grid = SVR()\n",
    "\n",
    "\n",
    "# parameters = {\n",
    "#     'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#     'degree': [3,6,9],\n",
    "#     'gamma': ['scale','auto']\n",
    "\n",
    "# }\n",
    "\n",
    "# grid_svr = GridSearchCV(SVR_grid, param_grid = parameters, n_jobs=6, verbose=3, scoring = 'neg_median_absolute_error', cv = 5)\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# grid_svr.fit(X_train_scaled,y_train)\n",
    " \n",
    "\n",
    "# print('best params')\n",
    "# print(grid_svr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6628639047729248\n"
     ]
    }
   ],
   "source": [
    "# X_val_scaled = scaler.transform(X_val)\n",
    "# y_val_pred_grid = grid_svr.predict(X_val_scaled)\n",
    "# medae_grid = median_absolute_error(y_val, y_val_pred_grid)\n",
    "# print(medae_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline using the grid-optimized SVR model\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "pipeline_grid_svr = Pipeline([('scaler', scaler),\n",
    "                          ('regressor', SVR(degree = 6, gamma = 'scale', kernel = 'poly'))])\n",
    "\n",
    "pipeline_grid_svr.fit(X, y)\n",
    "\n",
    "y_test_pred = pipeline_grid_svr.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'id': X_test.index,\n",
    "                       'emission': y_test_pred})\n",
    "\n",
    "from datetime import date, datetime\n",
    "now = datetime.now()\n",
    "today_str = now.strftime(\"%d%m%Y_%H%M\")\n",
    "\n",
    "subm_file_name = \"submissions/submission_\"+today_str+\".csv\"\n",
    "\n",
    "output.to_csv(subm_file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on Kaggle: 0.6566"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing submission file\n",
    "New model (LightGBM) with all features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_light.fit(X,y)\n",
    "\n",
    "# y_test_pred = pipeline_light.predict(X_test)\n",
    "\n",
    "# output = pd.DataFrame({'id': X_test.index,\n",
    "#                        'emission': y_test_pred})\n",
    "\n",
    "# from datetime import date, datetime\n",
    "# now = datetime.now()\n",
    "# today_str = now.strftime(\"%d%m%Y_%H%M\")\n",
    "\n",
    "# subm_file_name = \"submissions/submission_\"+today_str+\".csv\"\n",
    "\n",
    "# output.to_csv(subm_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only the top 5 correlation features\n",
    "best_corr_feats = ['atomicweight_Average', 'density_Average',# 'allelectrons_Average',\n",
    "                   'el_neg_chi_Average', 'ionenergy_Average', 'R_cov_element_Average']\n",
    "\n",
    "X_corr = X[best_corr_feats]\n",
    "\n",
    "X_train_corr, X_val_corr, y_train_corr, y_val_corr = train_test_split(X_corr, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "Best Median Absolute Error with LightGBM | MedAE: 0.5845266262717335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Baseline': 0.9935564263469043,\n",
       " 'LightGBM': 0.5845266262717335,\n",
       " 'Random Forest': 0.6731373350042418,\n",
       " 'Decision Tree': 0.6348837209302376,\n",
       " 'SVR': 0.7117191991904059}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = preprocessing.MinMaxScaler()\n",
    "\n",
    "pipeline_light_2 = Pipeline(steps=[('processing',process),\n",
    "                     ('regressor', lgb.LGBMRegressor(random_state=42, bagging_fraction = 0.6,\n",
    "                                                          boosting = 'gbdt', feature_fraction = 0.6,\n",
    "                                                          learning_rate = 0.05, max_depth = 15,\n",
    "                                                          num_leaves = 15, objective= 'mae'))])\n",
    "\n",
    "pipeline_rf_2 = Pipeline(steps = [('processing', process),\n",
    "                                ('regressor',RandomForestRegressor(max_depth=15,random_state = 42))])\n",
    "\n",
    "pipeline_dt_2 = Pipeline(steps=[('processing', process),\n",
    "                              ('regressor', DecisionTreeRegressor(max_depth=15,random_state = 42))])\n",
    "\n",
    "pipeline_svr_2 = Pipeline(steps=[('processing', process),\n",
    "                              ('regressor', SVR(degree = 6, gamma = 'scale', kernel = 'poly'))])\n",
    "\n",
    "\n",
    "pipelines_2 = [pipeline_base, pipeline_light_2, pipeline_rf_2, pipeline_dt_2, pipeline_svr_2]\n",
    "pipe_dict_2 = {0: 'Baseline', 1: 'LightGBM', 2:'Random Forest', 3: 'Decision Tree', 4: 'SVR'}\n",
    "\n",
    "for pipe in pipelines_2:\n",
    "    pipe.fit(X_train_corr, y_train_corr)\n",
    "\n",
    "best_precision = 0.0\n",
    "best_regressor = 0\n",
    "best_medae = 10\n",
    "best_pipeline = ''\n",
    "prediction_dict_2={}\n",
    "\n",
    "for i, model in enumerate(pipelines_2) : \n",
    "    y_val_pred = model.predict(X_val_corr)\n",
    "    medae = median_absolute_error(y_val_corr, y_val_pred)\n",
    "\n",
    "    prediction_dict_2[pipe_dict_2[i]] = medae\n",
    "\n",
    "    if medae < best_medae:\n",
    "        best_medae = medae\n",
    "        best_pipeline = model\n",
    "        best_regressor = i\n",
    "print('Best Median Absolute Error with {} | MedAE: {}'.format(pipe_dict_2[best_regressor],best_medae))\n",
    "\n",
    "prediction_dict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n"
     ]
    }
   ],
   "source": [
    "# Checking which feature has the biggest impact on score\n",
    "medae_dict = {}\n",
    "for i in X.columns:\n",
    "    X_i =  X.copy()\n",
    "    X_i = X_i.drop(columns=i)\n",
    "    X_train_i, X_val_i, y_train_i, y_val_i = train_test_split(X_i, y, test_size=0.3, random_state=42)\n",
    "    pipeline_light_2.fit(X_train_i, y_train_i)\n",
    "    y_val_pred_i = pipeline_light_2.predict(X_val_i)\n",
    "    medae_i = median_absolute_error(y_val_i, y_val_pred_i)\n",
    "    medae_dict[i] = medae_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "MedAE using all features: 0.6527384090608557\n",
      "MedAE when removing allelectrons_Total: 0.5581649783897231\n",
      "MedAE when removing density_Total: 0.5468895977000372\n",
      "MedAE when removing allelectrons_Average: 0.5493471907771816\n",
      "MedAE when removing val_e_Average: 0.5552067201290045\n",
      "MedAE when removing atomicweight_Average: 0.5549171638250172\n",
      "MedAE when removing ionenergy_Average: 0.5550724789371309\n",
      "MedAE when removing el_neg_chi_Average: 0.5402329076079049\n",
      "MedAE when removing R_vdw_element_Average: 0.5322745309485315\n",
      "MedAE when removing R_cov_element_Average: 0.5367730990769446\n",
      "MedAE when removing zaratio_Average: 0.5422356566340829\n",
      "MedAE when removing density_Average: 0.534744228406832\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "pipeline_light_2.fit(X_train, y_train)\n",
    "y_val_pred_i = pipeline_light_2.predict(X_val)\n",
    "medae_all = median_absolute_error(y_val, y_val_pred)\n",
    "print('MedAE using all features: {}'.format(medae_all))\n",
    "\n",
    "for i,k in enumerate(medae_dict):\n",
    "    print('MedAE when removing {}: {}'.format(k, medae_dict[k]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median Absolute Error less affected by removing:\n",
    "> 1. total number of electrons\n",
    "> 2. average number of valence electrons\n",
    "> 3. average atomic weight\n",
    "\n",
    "This is consistent with the correlation results.\n",
    "\n",
    "The score improves when removing:\n",
    "> 1. covalent or van der Walls radii\n",
    "> 2. average density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "0.522685313716571\n"
     ]
    }
   ],
   "source": [
    "X_corr_2 = X.drop(columns=['R_vdw_element_Average', 'density_Average'])\n",
    "\n",
    "X_train_corr_2, X_val_corr_2, y_train_corr_2, y_val_corr_2 = train_test_split(X_corr_2, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "pipeline_light_2.fit(X_train_corr_2, y_train_corr_2)\n",
    "y_val_pred_corr_2 = pipeline_light_2.predict(X_val_corr_2)\n",
    "medae_corr_2 = median_absolute_error(y_val_corr_2, y_val_pred_corr_2)\n",
    "print(medae_corr_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Score: 0.5153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_light_2.fit(X_corr_2,y)\n",
    "\n",
    "# X_test_corr_2 = X_test.drop(columns=['R_vdw_element_Average', 'density_Average'])\n",
    "# y_test_pred = pipeline_light_2.predict(X_test_corr_2)\n",
    "\n",
    "# output = pd.DataFrame({'id': X_test_corr_2.index,\n",
    "#                        'emission': y_test_pred})\n",
    "\n",
    "# from datetime import date, datetime\n",
    "# now = datetime.now()\n",
    "# today_str = now.strftime(\"%d%m%Y_%H%M\")\n",
    "\n",
    "# subm_file_name = \"submissions/submission_\"+today_str+\".csv\"\n",
    "\n",
    "# output.to_csv(subm_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "Best Median Absolute Error with LightGBM | MedAE: 0.5878001035211016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Baseline': 0.9935564263469043,\n",
       " 'LightGBM': 0.5878001035211016,\n",
       " 'Random Forest': 0.670857332556424,\n",
       " 'Decision Tree': 0.6348837209302376,\n",
       " 'SVR': 0.9915724532192645}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = preprocessing.RobustScaler()\n",
    "\n",
    "pipeline_light_3 = Pipeline(steps=[('processing',process),\n",
    "                     ('regressor', lgb.LGBMRegressor(random_state=42, bagging_fraction = 0.6,\n",
    "                                                          boosting = 'gbdt', feature_fraction = 0.6,\n",
    "                                                          learning_rate = 0.05, max_depth = 15,\n",
    "                                                          num_leaves = 15, objective= 'mae'))])\n",
    "\n",
    "pipeline_rf_3 = Pipeline(steps = [('processing', process),\n",
    "                                ('regressor',RandomForestRegressor(max_depth=15,random_state = 42))])\n",
    "\n",
    "pipeline_dt_3 = Pipeline(steps=[('processing', process),\n",
    "                              ('regressor', DecisionTreeRegressor(max_depth=15,random_state = 42))])\n",
    "\n",
    "pipeline_svr_3 = Pipeline(steps=[('processing', process),\n",
    "                              ('regressor', SVR(degree = 6, gamma = 'scale', kernel = 'poly'))])\n",
    "\n",
    "\n",
    "pipelines_3 = [pipeline_base, pipeline_light_3, pipeline_rf_3, pipeline_dt_3, pipeline_svr_3]\n",
    "pipe_dict_3 = {0: 'Baseline', 1: 'LightGBM', 2:'Random Forest', 3: 'Decision Tree', 4: 'SVR'}\n",
    "\n",
    "for pipe in pipelines_3:\n",
    "    pipe.fit(X_train_corr, y_train_corr)\n",
    "\n",
    "best_precision = 0.0\n",
    "best_regressor = 0\n",
    "best_medae = 10\n",
    "best_pipeline = ''\n",
    "prediction_dict_3={}\n",
    "\n",
    "for i, model in enumerate (pipelines_3) : \n",
    "    y_val_pred = model.predict(X_val_corr)\n",
    "    medae = median_absolute_error(y_val_corr, y_val_pred)\n",
    "\n",
    "    prediction_dict_3[pipe_dict_3[i]] = medae\n",
    "\n",
    "    if medae < best_medae:\n",
    "        best_medae = medae\n",
    "        best_pipeline = model\n",
    "        best_regressor = i\n",
    "print('Best Median Absolute Error with {} | MedAE: {}'.format(pipe_dict_3[best_regressor],best_medae))\n",
    "\n",
    "prediction_dict_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "0.5299773378723014\n"
     ]
    }
   ],
   "source": [
    "pipeline_light_3.fit(X_train_corr_2, y_train_corr_2)\n",
    "y_val_pred_corr_3 = pipeline_light_3.predict(X_val_corr_2)\n",
    "medae_corr_2 = median_absolute_error(y_val_corr_2, y_val_pred_corr_3)\n",
    "print(medae_corr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n"
     ]
    }
   ],
   "source": [
    "# pipeline_light_3.fit(X_corr_2,y)\n",
    "\n",
    "# X_test_corr_3 = X_test.drop(columns=['R_vdw_element_Average', 'density_Average'])\n",
    "# y_test_pred = pipeline_light_3.predict(X_test_corr_3)\n",
    "\n",
    "# output = pd.DataFrame({'id': X_test_corr_3.index,\n",
    "#                        'emission': y_test_pred})\n",
    "\n",
    "# from datetime import date, datetime\n",
    "# now = datetime.now()\n",
    "# today_str = now.strftime(\"%d%m%Y_%H%M\")\n",
    "\n",
    "# subm_file_name = \"submissions/submission_\"+today_str+\".csv\"\n",
    "\n",
    "# output.to_csv(subm_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Score: 0.5130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Baseline': 0.9555663913173742, 'LightGBM': 0.6452822745961022, 'Random Forest': 0.645478039694277, 'Decision Tree': 0.7000000000000002, 'SVR': 0.6527384090608557}\n",
      "{'Baseline': 0.9935564263469043, 'LightGBM': 0.5845266262717335, 'Random Forest': 0.6731373350042418, 'Decision Tree': 0.6348837209302376, 'SVR': 0.7117191991904059}\n",
      "{'Baseline': 0.9935564263469043, 'LightGBM': 0.5878001035211016, 'Random Forest': 0.670857332556424, 'Decision Tree': 0.6348837209302376, 'SVR': 0.9915724532192645}\n"
     ]
    }
   ],
   "source": [
    "print(prediction_dict)\n",
    "print(prediction_dict_2)\n",
    "print(prediction_dict_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from model optimization:\n",
    "> 1. RobustScaler improves performance slightly\n",
    "> 2. Reducing the number of features seems to improve MedAE\n",
    "> 3. LightGBM seems, overall, the best model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
